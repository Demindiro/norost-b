From 9cef00e22d541ace693dbd2b58042d2528cf6255 Mon Sep 17 00:00:00 2001
From: David Hoppenbrouwers <david@salt-inc.org>
Date: Wed, 20 Apr 2022 15:25:24 +0200
Subject: [PATCH 22/43] Implement proper heap allocator

---
 Cargo.toml                                    |  1 +
 library/std/src/sys/norostb/alloc.rs          | 59 +++++++++++--------
 .../std/src/sys/norostb/thread_local_key.rs   |  3 +-
 3 files changed, 36 insertions(+), 27 deletions(-)

diff --git a/Cargo.toml b/Cargo.toml
index 7e0ea2765bd..0f98d7de9cf 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -125,6 +125,7 @@ rustfmt-nightly = { path = "src/tools/rustfmt" }
 # See comments in `src/tools/rustc-workspace-hack/README.md` for what's going on
 # here
 rustc-workspace-hack = { path = 'src/tools/rustc-workspace-hack' }
+#slabmalloc = { git = "https://git.sr.ht/~demindiro/rust-slabmalloc", branch = "norost" }
 
 # See comments in `library/rustc-std-workspace-core/README.md` for what's going on
 # here
diff --git a/library/std/src/sys/norostb/alloc.rs b/library/std/src/sys/norostb/alloc.rs
index 5a589bd14b4..80664e9fd25 100644
--- a/library/std/src/sys/norostb/alloc.rs
+++ b/library/std/src/sys/norostb/alloc.rs
@@ -1,48 +1,57 @@
-use crate::alloc::{GlobalAlloc, Layout, System};
-use crate::ptr;
+use crate::alloc::{Allocator as Alloc, GlobalAlloc, Layout, System};
+use crate::ptr::{self, NonNull};
+use crate::sys_common::mutex::StaticMutex;
+use norostb_rt::alloc::Allocator;
 
-#[repr(align(16))]
-#[derive(Clone, Copy)]
-struct E([u8; 16]);
-static mut HEAP: [E; 4096] = [E([0; 16]); 4096];
-static mut HEAP_I: usize = 0;
+static ALLOCATOR_LOCK: StaticMutex = StaticMutex::new();
+static mut ALLOCATOR: Allocator = Allocator::new();
 
 #[stable(feature = "alloc_system_type", since = "1.28.0")]
 unsafe impl GlobalAlloc for System {
     #[inline]
     unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
-        unsafe { self.alloc_zeroed(layout) }
+        unsafe {
+            let _guard = ALLOCATOR_LOCK.lock();
+            ALLOCATOR.allocate(layout).map_or(ptr::null_mut(), |p| p.as_ptr().as_mut_ptr())
+        }
     }
 
     #[inline]
     unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {
         unsafe {
-            let s = layout.pad_to_align().size();
-            let s = (s + 15) & !15;
-            let p = HEAP.as_ptr().add(HEAP_I);
-            HEAP_I += s / 16;
-            p as *mut u8
+            let _guard = ALLOCATOR_LOCK.lock();
+            ALLOCATOR.allocate_zeroed(layout).map_or(ptr::null_mut(), |p| p.as_ptr().as_mut_ptr())
         }
     }
 
     #[inline]
-    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {}
+    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
+        debug_assert!(!ptr.is_null());
+        unsafe {
+            let _guard = ALLOCATOR_LOCK.lock();
+            ALLOCATOR.deallocate(NonNull::new_unchecked(ptr), layout)
+        }
+    }
 
     #[inline]
     unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {
-        if layout.size() >= new_size {
-            return ptr;
-        }
-        // SAFETY: the caller has to ensure new_size doesn't overflow
-        let new_layout = unsafe { Layout::from_size_align_unchecked(new_size, layout.align()) };
-        // SAFETY: the caller has to ensure new_size is non-zero
-        let new_ptr = unsafe { self.alloc_zeroed(new_layout) };
-        if !new_ptr.is_null() {
-            // SAFETY: the old and new pointer are both valid and cannot overlap.
+        debug_assert!(!ptr.is_null());
+        let old_layout = layout;
+        if let Ok(new_layout) = Layout::from_size_align(new_size, layout.align()) {
             unsafe {
-                ptr::copy_nonoverlapping(ptr, new_ptr, layout.size().min(new_size));
+                let _guard = ALLOCATOR_LOCK.lock();
+                if new_layout.size() > old_layout.size() {
+                    ALLOCATOR
+                        .grow(NonNull::new_unchecked(ptr), old_layout, new_layout)
+                        .map_or(ptr::null_mut(), |p| p.as_ptr().as_mut_ptr())
+                } else {
+                    ALLOCATOR
+                        .shrink(NonNull::new_unchecked(ptr), old_layout, new_layout)
+                        .map_or(ptr::null_mut(), |p| p.as_ptr().as_mut_ptr())
+                }
             }
+        } else {
+            ptr::null_mut()
         }
-        new_ptr
     }
 }
diff --git a/library/std/src/sys/norostb/thread_local_key.rs b/library/std/src/sys/norostb/thread_local_key.rs
index 458124bd4b3..cd369f2aade 100644
--- a/library/std/src/sys/norostb/thread_local_key.rs
+++ b/library/std/src/sys/norostb/thread_local_key.rs
@@ -14,8 +14,7 @@ pub(super) unsafe fn init_thread() {
         tls::init_thread::<_, ()>(|s| {
             Ok(NonNull::new(Box::into_raw(Box::<[u8]>::new_uninit_slice(s)) as *mut *mut ())
                 .unwrap())
-        })
-        .expect("failed to initialize TLS storage");
+        }).unwrap_or_else(|_| crate::intrinsics::abort())
     }
 }
 
-- 
2.30.2

